{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from question4 import *\n",
    "from comet_ml import Experiment\n",
    "import os\n",
    "from etape2_Q3 import *\n",
    "import numpy as np\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from matplotlib.gridspec import GridSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "my_key = os.environ.get(\"COMET_API_KEY\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/teylouniseifu/ift-6758-a22/16e84c4a101e4b749d7968d973883e23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp = Experiment(api_key=my_key, project_name='ift-6758-a22', workspace='teylouniseifu' )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "directory2015 = r'C:\\Users\\raph_\\PycharmProjects\\DS-GroupProject\\data_saved\\play_by_play\\2015\\regular'\n",
    "directory2016 = r'C:\\Users\\raph_\\PycharmProjects\\DS-GroupProject\\data_saved\\play_by_play\\2016\\regular'\n",
    "directory2017 = r'C:\\Users\\raph_\\PycharmProjects\\DS-GroupProject\\data_saved\\play_by_play\\2017\\regular'\n",
    "directory2018 = r'C:\\Users\\raph_\\PycharmProjects\\DS-GroupProject\\data_saved\\play_by_play\\2018\\regular'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df2015 = create_full_df(directory2015)\n",
    "df2016 = create_full_df(directory2016)\n",
    "df2017 = create_full_df(directory2017)\n",
    "df2018 = create_full_df(directory2018)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df_train = pd.concat([df2015, df2016, df2017], ignore_index=True)\n",
    "df_val = df2018\n",
    "df_train = df_train.dropna(subset=\"Distance\")\n",
    "df_val = df_val.dropna(subset=\"Distance\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "X_train_dna = df_train[[\"Distance\"]]\n",
    "y_train = df_train[\"Est_un_but\"]\n",
    "X_val_dna = df_val[[\"Distance\"]]\n",
    "y_val = df_val[\"Est_un_but\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "y_score_dna, y_prob_dna, clf_dna = logistic_regression(X_train_dna, y_train, X_val_dna)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [11], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m fpr_dna, tpr_dna, roc_auc_dna \u001B[38;5;241m=\u001B[39m \u001B[43mget_roc_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_prob_dna\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\ift-6758-a22\\etape2_Q3.py:26\u001B[0m, in \u001B[0;36mget_roc_data\u001B[1;34m(y_test, y_prob)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_roc_data\u001B[39m(y_test, y_prob: np\u001B[38;5;241m.\u001B[39marray):\n\u001B[1;32m---> 26\u001B[0m     fpr, tpr, _ \u001B[38;5;241m=\u001B[39m \u001B[43mroc_curve\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_prob\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m     roc_auc \u001B[38;5;241m=\u001B[39m auc(fpr, tpr)\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fpr, tpr, roc_auc\n",
      "File \u001B[1;32m~\\PycharmProjects\\ift-6758-a22\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:981\u001B[0m, in \u001B[0;36mroc_curve\u001B[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001B[0m\n\u001B[0;32m    892\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mroc_curve\u001B[39m(\n\u001B[0;32m    893\u001B[0m     y_true, y_score, \u001B[38;5;241m*\u001B[39m, pos_label\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, drop_intermediate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    894\u001B[0m ):\n\u001B[0;32m    895\u001B[0m     \u001B[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001B[39;00m\n\u001B[0;32m    896\u001B[0m \n\u001B[0;32m    897\u001B[0m \u001B[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    979\u001B[0m \n\u001B[0;32m    980\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 981\u001B[0m     fps, tps, thresholds \u001B[38;5;241m=\u001B[39m \u001B[43m_binary_clf_curve\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    982\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\n\u001B[0;32m    983\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    985\u001B[0m     \u001B[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001B[39;00m\n\u001B[0;32m    986\u001B[0m     \u001B[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001B[39;00m\n\u001B[0;32m    987\u001B[0m     \u001B[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    992\u001B[0m     \u001B[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001B[39;00m\n\u001B[0;32m    993\u001B[0m     \u001B[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001B[39;00m\n\u001B[0;32m    994\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m drop_intermediate \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(fps) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\ift-6758-a22\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:740\u001B[0m, in \u001B[0;36m_binary_clf_curve\u001B[1;34m(y_true, y_score, pos_label, sample_weight)\u001B[0m\n\u001B[0;32m    738\u001B[0m y_type \u001B[38;5;241m=\u001B[39m type_of_target(y_true, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    739\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m (y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m pos_label \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)):\n\u001B[1;32m--> 740\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m format is not supported\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(y_type))\n\u001B[0;32m    742\u001B[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001B[0;32m    743\u001B[0m y_true \u001B[38;5;241m=\u001B[39m column_or_1d(y_true)\n",
      "\u001B[1;31mValueError\u001B[0m: continuous format is not supported"
     ]
    }
   ],
   "source": [
    "fpr_dna, tpr_dna, roc_auc_dna = get_roc_data(y_prob_dna[:,1], y_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "perc_dna, perc_values_dna, num_goals_dna = get_percentile_goal_chance(y_prob_dna[:,1], y_val)\n",
    "cum_values_dna = np.cumsum(num_goals_dna)\n",
    "sum = np.sum(num_goals_dna)/100\n",
    "cum_values_dna = [i/sum for i in cum_values_dna]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "exp.log_metric(\"roc\", roc_auc_dna)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m exp\u001B[38;5;241m.\u001B[39mend()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'exp' is not defined"
     ]
    }
   ],
   "source": [
    "exp.end()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
